# -*- coding: utf-8 -*-
"""BDA_FINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zh-uC-b7o1xFvAjEfZix2r-4HWEcqSEa
"""

!pip install opendatasets

import opendatasets as od

{"username":"praveend21alr033","key":"4e17ac97539cc2a48d23acda5e485614"}

!pip install pyspark

from pyspark.sql import SparkSession
import pandas as pd
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml.recommendation import ALS
from pyspark.sql.functions import *
from pyspark.sql import Row
import os
from pyspark.sql import SparkSession
from pyspark.ml.feature import StringIndexer

spark = SparkSession.builder.appName('Recommender').getOrCreate()
spark

{"username":"praveend21alr033","key":"2bc40415403e04550e64a61290bb4575"}

od.download('https://www.kaggle.com/datasets/skillsmuggler/amazon-ratings')

data=spark.read.csv('/content/amazon-ratings/ratings_Beauty.csv',header=True)
data.show()

data=data.limit(20000)

data.show()

"""PREPROCESSING"""

data.toPandas().shape

data=data.dropna()

data.toPandas().shape

"""1.REPLACING THE STRING WITH FUNCTION CALLED STRINGINDEXER"""

st1= StringIndexer(inputCol='ProductId',outputCol='productIndex')
st2= StringIndexer(inputCol='UserId',outputCol='userIndex')
st1=st1.fit(data)
st2=st2.fit(data)
data=st1.transform(data)
data=st2.transform(data)
data.show()

"""4.TYPE CASTING"""

from pyspark.sql.functions import col
data = data.withColumn("productIndex", col("productIndex").cast("int"))
data = data.withColumn("userIndex", col("userIndex").cast("int"))
data = data.withColumn("Rating", col("Rating").cast("int"))
data.show()

data.select(max("productIndex")).collect()[0][0]

data.select("productIndex").distinct().toPandas().shape

"""SPLITTING TRAIN AND TEST"""

train_data, test_data = data.randomSplit([0.8, 0.2])

"""BUILDING THE MODEL"""

als = ALS(maxIter=5, regParam=0.01, userCol="userIndex", itemCol="productIndex", ratingCol="Rating", coldStartStrategy="drop")

"""FITTING THE MODEL"""

model=als.fit(train_data)

"""PREDICTION OF TRAINED MODEL"""

predictions = model.transform(test_data)

"""TESTING THE MODEL USING OUR DATA"""

userRecs = model.recommendForAllUsers(10)

from pyspark.sql.functions import col
user_id =  2944
user_recommendations = userRecs.filter(col("userIndex") == user_id).select("recommendations")

user_recommendations

print(f"Top 3 recommendations for user {user_id}:")
user_recommendations.show(truncate=False)

evaluator = RegressionEvaluator(metricName="rmse", labelCol="Rating",predictionCol="prediction")
rmse = evaluator.evaluate(predictions)
print("Root-mean-square error = " + str(rmse))

from pyspark.ml.recommendation import ALS
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml import Pipeline
from pyspark.sql import SparkSession


# Create an ALS model
als = ALS(
    rank=30,
    maxIter=4,
    regParam=0.1,
    userCol='userIndex',
    itemCol='productIndex',
    ratingCol='Rating',
    coldStartStrategy='drop',
    implicitPrefs=False
)

# Create a RegressionEvaluator
evaluator = RegressionEvaluator(metricName='mae', labelCol='Rating', predictionCol='prediction')

# Define a pipeline
pipeline = Pipeline(stages=[als])

# Fit the model in the pipeline on the training data
model = pipeline.fit(train_data)

# Make predictions on the test data
predictions = model.transform(test_data)

# Evaluate the model using the RegressionEvaluator
mae = evaluator.evaluate(predictions)

print(f'MAE (Test) = {mae}')

from pyspark.ml.tuning import CrossValidator, ParamGridBuilder

# Define the ALS model
als = ALS(
    userCol='userIndex',
    itemCol='productIndex',
    ratingCol='Rating',
    coldStartStrategy='drop',
    implicitPrefs=False
)

# Define a parameter grid for hyperparameter tuning
paramGrid = (ParamGridBuilder()
             .addGrid(als.regParam, [0.01])
             .addGrid(als.rank, [10])
             .addGrid(als.maxIter, [15])
             .build())

# Create a RegressionEvaluator
evaluator = RegressionEvaluator(metricName='mae', labelCol='Rating', predictionCol='prediction')

# Create a cross-validator
crossval = CrossValidator(
    estimator=als,
    estimatorParamMaps=paramGrid,
    evaluator=evaluator,
    numFolds=5
)

# Fit the model with hyperparameter tuning on the training data
cvModel = crossval.fit(train_data)

# Get the best model from cross-validation
best_model = cvModel.bestModel

# Make predictions on the test data using the best model
predictions = best_model.transform(test_data)

# Evaluate the model using the RegressionEvaluator
mae = evaluator.evaluate(predictions)

print ("**Best Model**")
print ("Rank: ", best_model)
print (" MaxIter: ", str(best_model._java_obj.parent().getMaxIter()))
print (" RegParam:",  best_model._java_obj.parent().regParam())

#Generate predictions and evaluate using RMSE
predictions=best_model.transform(test_data)
rmse = evaluator.evaluate(predictions)

#Print RMSE
print ("RMSE = "+str(rmse))

product_recommendation = best_model.recommendForAllUsers(10)
product_recommendation.show()